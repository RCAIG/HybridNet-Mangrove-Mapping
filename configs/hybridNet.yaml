train:
  seed: 1999
  epochs: 512
  interval: 16
  #pretrain: pretrain.pth

test:
  seed: 1999
  test_topk_per_scene: 100
  test_score_thresh: 0.0
  test_npoint_thresh: 100

dataloader:
  train:
    "/localssd/longjie/HybridNet/train"
  test:
    "/localssd/longjie/HybridNet/test"

model:
  num_layer: 5
  blocks: 5
  block_reps: 2
  media: 32
  normalize_before: True
  return_blocks: True
  pool: mean
  num_class: 18
  decoder:
    num_layer: 6
    num_query: 400
    d_model: 256
    nhead: 8
    hidden_dim: 1024
    dropout: 0.0
    activation_fn: gelu
    iter_pred: True
    attn_mask: True
    pe: False
  criterion:
    loss_weight: [0.5, 1.0, 1.0, 0.5]
    cost_weight: [0.5, 1.0, 1.0]
    non_object_weight: 0.1
  test_cfg:
    topk_insts: 100
    score_thr: 0.0
    npoint_thr: 100
  norm_eval: False
  fix_module: []

optimizer:
  type: AdamW
  lr: 0.0001
  weight_decay: 0.05

lr_scheduler:
  type: PolyLR
  max_iters: 512
  power: 0.9
  constant_ending: 0.0

max_lr: 0.0001
epoch: 150
weight_decay: 0.0001
batch_size: 8
smin: 0.0001
smax: 1.77119994

steps_per_epoch: 2500
# Those arguments within experiment defines which model, dataset and task to be created for benchmarking
# parameters for Weights and Biases
wandb:
  entity: "RCAIG" #TO ADAPT: change to your own wandb account name
  project: Hybrid-Mangrove 
  log: True
  notes: "MangroveMap"
  name: "MangroveMap" #TO ADAPT: specify name of experiment that will be shown on wandb
  id:
  public: True # It will be display the model within wandb log, else not.
